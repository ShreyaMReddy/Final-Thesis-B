tokenizer_config.json: 100%
 25.0/25.0 [00:00<00:00, 3.12kB/s]
vocab.json: 100%
 899k/899k [00:00<00:00, 1.37MB/s]
merges.txt: 100%
 456k/456k [00:00<00:00, 2.01MB/s]
tokenizer.json: 100%
 1.36M/1.36M [00:00<00:00, 2.14MB/s]
config.json: 100%
 481/481 [00:00<00:00, 60.4kB/s]
Dataset:  lun
loading news articles
model.safetensors: 100%
 499M/499M [00:01<00:00, 551MB/s]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:15<00:00,  3.44it/s]
Iter 000 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:15<00:00,  3.44it/s]
Iter 000 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 000 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.43it/s]
Iter 000 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:15<00:00,  3.44it/s]
Iter 000 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:12<00:00, 30.60it/s]
100%|██████████| 375/375 [00:11<00:00, 32.23it/s]
-----------------End of Iter 000-----------------
['Global Test Accuracy:0.9333', 'Precision:0.9336', 'Recall:0.9333', 'F1:0.9333']
-----------------Restyle-----------------
['Global Test Accuracy:0.8707', 'Precision:0.8722', 'Recall:0.8707', 'F1:0.8705']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 001 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 001 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 001 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 001 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 001 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.86it/s]
100%|██████████| 375/375 [00:11<00:00, 32.23it/s]
-----------------End of Iter 001-----------------
['Global Test Accuracy:0.9380', 'Precision:0.9391', 'Recall:0.9380', 'F1:0.9380']
-----------------Restyle-----------------
['Global Test Accuracy:0.8473', 'Precision:0.8535', 'Recall:0.8473', 'F1:0.8467']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 002 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 002 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 002 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 002 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 002 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.85it/s]
100%|██████████| 375/375 [00:11<00:00, 32.22it/s]
-----------------End of Iter 002-----------------
['Global Test Accuracy:0.9240', 'Precision:0.9273', 'Recall:0.9240', 'F1:0.9239']
-----------------Restyle-----------------
['Global Test Accuracy:0.8607', 'Precision:0.8607', 'Recall:0.8607', 'F1:0.8607']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:15<00:00,  3.44it/s]
Iter 003 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 003 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 003 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 003 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 003 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.85it/s]
100%|██████████| 375/375 [00:11<00:00, 32.24it/s]
-----------------End of Iter 003-----------------
['Global Test Accuracy:0.9327', 'Precision:0.9344', 'Recall:0.9327', 'F1:0.9326']
-----------------Restyle-----------------
['Global Test Accuracy:0.8520', 'Precision:0.8530', 'Recall:0.8520', 'F1:0.8519']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:15<00:00,  3.44it/s]
Iter 004 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.43it/s]
Iter 004 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 004 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 004 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 004 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.85it/s]
100%|██████████| 375/375 [00:11<00:00, 32.23it/s]
-----------------End of Iter 004-----------------
['Global Test Accuracy:0.9313', 'Precision:0.9344', 'Recall:0.9313', 'F1:0.9312']
-----------------Restyle-----------------
['Global Test Accuracy:0.8660', 'Precision:0.8662', 'Recall:0.8660', 'F1:0.8660']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:15<00:00,  3.44it/s]
Iter 005 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 005 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 005 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.43it/s]
Iter 005 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 005 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.85it/s]
100%|██████████| 375/375 [00:11<00:00, 32.24it/s]
-----------------End of Iter 005-----------------
['Global Test Accuracy:0.9227', 'Precision:0.9268', 'Recall:0.9227', 'F1:0.9225']
-----------------Restyle-----------------
['Global Test Accuracy:0.8673', 'Precision:0.8698', 'Recall:0.8673', 'F1:0.8671']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 006 | Epoch 00000 | Train Acc. 0.7500
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.43it/s]
Iter 006 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 006 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 006 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 006 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.81it/s]
100%|██████████| 375/375 [00:11<00:00, 32.23it/s]
-----------------End of Iter 006-----------------
['Global Test Accuracy:0.9227', 'Precision:0.9241', 'Recall:0.9227', 'F1:0.9226']
-----------------Restyle-----------------
['Global Test Accuracy:0.8473', 'Precision:0.8475', 'Recall:0.8473', 'F1:0.8473']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 007 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 007 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 007 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 007 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 007 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.85it/s]
100%|██████████| 375/375 [00:11<00:00, 32.23it/s]
-----------------End of Iter 007-----------------
['Global Test Accuracy:0.9213', 'Precision:0.9213', 'Recall:0.9213', 'F1:0.9213']
-----------------Restyle-----------------
['Global Test Accuracy:0.8413', 'Precision:0.8447', 'Recall:0.8413', 'F1:0.8409']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 008 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 008 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.43it/s]
Iter 008 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 008 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:18<00:00,  3.42it/s]
Iter 008 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.78it/s]
100%|██████████| 375/375 [00:11<00:00, 32.17it/s]
-----------------End of Iter 008-----------------
['Global Test Accuracy:0.9153', 'Precision:0.9156', 'Recall:0.9153', 'F1:0.9153']
-----------------Restyle-----------------
['Global Test Accuracy:0.8587', 'Precision:0.8591', 'Recall:0.8587', 'F1:0.8586']
Dataset:  lun
loading news articles
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.44it/s]
Iter 009 | Epoch 00000 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:16<00:00,  3.43it/s]
Iter 009 | Epoch 00001 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 009 | Epoch 00002 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 009 | Epoch 00003 | Train Acc. 1.0000
loading news augmentations
Dataset:  lun
100%|██████████| 1500/1500 [07:17<00:00,  3.43it/s]
Iter 009 | Epoch 00004 | Train Acc. 1.0000
100%|██████████| 375/375 [00:11<00:00, 31.68it/s]
100%|██████████| 375/375 [00:11<00:00, 32.20it/s]
-----------------End of Iter 009-----------------
['Global Test Accuracy:0.9253', 'Precision:0.9256', 'Recall:0.9253', 'F1:0.9253']
-----------------Restyle-----------------
['Global Test Accuracy:0.8587', 'Precision:0.8632', 'Recall:0.8587', 'F1:0.8582']
Total_Test_Accuracy: 0.9267|Prec_Macro: 0.9282|Rec_Macro: 0.9267|F1_Macro: 0.9266
Restyle_Test_Accuracy: 0.8570|Prec_Macro: 0.8590|Rec_Macro: 0.8570|F1_Macro: 0.8568
